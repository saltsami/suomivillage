# Current Status & Next Steps (Live)

Updated: 2025-12-14

## What's implemented now

### Infrastructure & Setup
- ‚úÖ Repo scaffold per `repo_structure.txt`
- ‚úÖ `infra/docker-compose.yml` with CPU/GPU llama.cpp profiles
- ‚úÖ `infra/.env` configured for **GPU mode** with **Qwen2.5 7B Instruct Q4_K_M** model
- ‚úÖ Migrations: `001_init.sql` (events/posts/jobs), `002_kickoff_tables.sql` (entities/profiles/relationships/memories/goals)

### Shared Packages
- ‚úÖ `packages/shared/settings.py`, `db.py`, `schemas.py`
- ‚úÖ `packages/shared/data_loader.py` loads canonical catalog
- ‚úÖ `packages/shared/data/event_types.json` in-tree

### Engine (`services/engine/app/runner.py`)
- ‚úÖ Seeds DB from catalog if empty (places, NPCs, profiles, relationship edges, goals)
- ‚úÖ Injects Day 1 seed events (17 events from catalog)
- ‚úÖ **Continuous simulation loop** with deterministic tick scheduler
- ‚úÖ **Post-Day1 routine event injector**:
  - Generates events every 10 ticks (~10 seconds)
  - NPC round-robin selection (deterministic)
  - 3 event types: LOCATION_VISIT, SMALL_TALK, CUSTOMER_INTERACTION
  - Place matching by type (sauna/beach, cafe, shop)
  - **Restart resilient**: Resumes from last tick index in DB
- ‚úÖ **Impact scoring system** (novelty, conflict, publicness, status, cascade potential)
- ‚úÖ **Event effects** applied to relationships and memories
- ‚úÖ Enqueues render jobs to Redis based on impact thresholds

### Workers (`services/workers/app/worker.py`)
- ‚úÖ Pops Redis jobs, fetches author profile
- ‚úÖ **Catalog-based prompt building** - loads `feed_prompt`, `chat_prompt`, `news_prompt` from catalog
- ‚úÖ **NPC profile integration** - uses personality, voice, name in prompts
- ‚úÖ **Natural Finnish event descriptions** - converts raw event data to readable Finnish
- ‚úÖ Calls LLM gateway and persists posts

### LLM Gateway (`services/llm_gateway/app/main.py`)
- ‚úÖ **Real llama.cpp adapter with Qwen2.5 7B Q4_K_M**
- ‚úÖ **JSON schema constraint** - forces structured output, prevents essays
- ‚úÖ Multi-endpoint fallback: `/v1/chat/completions` ‚Üí `/completion`
- ‚úÖ System message merging for models that don't support system role
- ‚úÖ JSON extraction with regex
- ‚úÖ Enhanced system instructions for Finnish content
- ‚úÖ CORS middleware

### API (`services/api/app/main.py`)
- ‚úÖ `/health`, `/posts`, `/events` read endpoints
- ‚úÖ CORS middleware
- ‚úÖ Admin endpoints stubbed

### Tools (`tools/`)
- ‚úÖ **`village_monitor.py`** - CLI activity feed for debugging
  - Live terminal view of events and posts
  - Filter by NPC, event type, channel
  - Usage: `./tools/village_monitor.py --live`

### Testing & Documentation
- ‚úÖ Smoke tests passing (API health, events, posts, LLM gateway)
- ‚úÖ **Pytest test suite** for LLM gateway:
  - `tests/test_gateway_contract.py` - schema validation, const locks
  - `tests/test_gateway_limits.py` - sentence limits, bad openers, Finnish check
  - `scripts/smoke_gateway.py` - standalone smoke script
  - `tests/prompts_fi.json` - 6 Finnish test prompts
- ‚úÖ **Comprehensive documentation**:
  - README.md with quick start guide
  - architecture.md with 5 Mermaid diagrams (system, event flow, tick flow, impact scoring, data models)
  - contracts.md (database schema, API contracts)
  - status-and-next.md (this file)

## How to run

See [README.md](../../README.md) for detailed quick start guide.

**Quick reference:**
```bash
cd koivulahti/infra
docker-compose --profile cpu up -d  # or --profile gpu
docker-compose logs engine -f
curl http://localhost:8082/events?limit=5
```

## Remaining work (prioritized)

### üî• Critical Path (Demo-ready)

1. ~~**Wire prompt templates from catalog**~~ ‚úÖ **DONE**
   - ~~Currently: Hardcoded prompts in workers/gateway~~
   - ~~Goal: Load `feed_prompt`, `chat_prompt`, `news_prompt` from `event_types.json`~~
   - ‚úÖ Workers now load catalog prompts and build channel-specific prompts
   - ‚úÖ NPC profiles integrated into prompts

2. **Daily NEWS digest**
   - Once per sim day, generate NEWS_PUBLISHED event
   - Pick top N events by impact score
   - Aggregate into daily village news post

3. **Nightly memory summaries**
   - Per NPC, write 1 summary memory per sim day
   - Compact older episodic memories (keep recent + important)

4. **Improve routine injector**
   - Add more event variety (conflicts, discoveries, transactions)
   - Goal-driven event selection (NPCs pursue goals)
   - Time-of-day awareness (morning routines, evening social)

### üõ°Ô∏è Production Quality

5. **Moderation + rate limits**
   - Apply `moderation_rules` from catalog before insert
   - Enforce `rate_limits` per channel/author
   - Block or flag problematic content

6. **World snapshots for replay**
   - Persist `world_snapshots` at sim day boundaries
   - Add replay script/endpoint
   - Verify determinism by replaying from seed

7. **Better LLM gateway**
   - ‚úÖ JSON repair logic for malformed responses (implemented)
   - ‚úÖ Dynamic JSON schema with const locks and per-channel limits
   - ‚úÖ 3-level fallback (json_schema ‚Üí json_object+schema ‚Üí json_object)
   - Response caching (Redis)
   - Prompt compression for long contexts

### ü§ñ Agent Decision MVP (Next Phase)

8. **NPC perception & retrieval**
   - Event-triggered perception (NPCs notice events)
   - Scheduled perception windows
   - Memory retrieval for decision context

9. **Action decision loop**
   - LLM outputs action JSON per `action_schema`
   - Engine validates action against rules
   - Emit resulting events deterministically

10. **Director system**
    - Narrative arc injectors
    - Tension/pacing management
    - Conflict escalation/resolution

### üìä Admin & UI (Later)

11. **Admin endpoints**
    - POST `/admin/run/start`, `/admin/run/stop`
    - POST `/admin/seed/reset`
    - POST `/admin/replay?from_tick=X`
    - GET `/admin/metrics` (events/posts counts, NPC states)

12. **Read-only village UI**
    - Event timeline
    - NPC profiles & relationships
    - Live feed/chat/news streams
    - Relationship graph visualization

## Session Summary (2025-12-16 PM) - Content Quality Overhaul

**Ongelma:** Postaukset olivat sekavia - kertoja-tyyli, 3. persoona, meta-puhe, v√§√§r√§ konteksti.

**Korjaukset:**

1. ‚úÖ **Draft-pohjainen render√∂inti** (worker.py)
   - `make_draft()` luo deterministisen pohjan eventist√§
   - LLM vain uudelleenmuotoilee hahmon √§√§nell√§
   - Ei en√§√§ "LLM keksii kaiken" -l√§hestymistapaa

2. ‚úÖ **Tiukempi system-ohje** (gateway main.py)
   - Pakolliset s√§√§nn√∂t: 1. persoona (FEED/CHAT), max 2 lausetta
   - Selke√§t esimerkit hyvist√§ ja huonoista postauksista
   - Kielletyt fraasit: "Kuvittele", "Tilannekuva", "Taustaksi" jne.

3. ‚úÖ **Quality gate + polish pass**
   - `has_banned_phrases()` tarkistaa kielletyt ilmaisut
   - `has_third_person_self()` tarkistaa 3. persoonan itsest√§
   - Automaattinen polish-pass jos ongelmia l√∂ytyy

4. ‚úÖ **Uudet testit** (test_gateway_limits.py)
   - `test_no_narrator_phrases` - ei meta-puhetta
   - `test_first_person_feed_chat` - 1. persoona
   - `test_no_third_person_self` - ei "Kaisa meni"

5. ‚úÖ **Village monitor parannukset**
   - Service status -rivi (‚óèdb ‚óèredis ‚óègateway jne.)
   - Leve√§mpi tekstikentt√§ postauksille
   - Shebang k√§ytt√§√§ venvi√§ automaattisesti

**Testitulokset:** 13 passed, 1 xfailed, 6 xpassed

**Merge:** `feature/llm-gateway-schema-improvements` ‚Üí `main` ‚úÖ

### üî¥ J√§ljell√§ olevat ongelmat (laatu ei viel√§ riitt√§v√§)

Postaukset teknisesti oikein (1. persoona, ei meta-puhetta) mutta **sis√§lt√∂ geneerist√§ ja toistavaa:**

```
[CHAT] Leena: Kahviolla. Sovitaan t√§st√§. Kuunnellaan kaikki.
[FEED] Riku: Asiakkaita kaupassa t√§n√§√§n. Fakta.
[CHAT] Aila: En sano nimi√§, mutta oon kahviolla. Kyll√§h√§n min√§ kuulin...
```

**Havaitut ongelmat:**
1. **Liian geneerinen** - kaikki sanoo vain "Kahviolla" tai "Asiakkaita X t√§n√§√§n"
2. **Toistuvat fraasit** - "No joo siis", "No katsotaan", "Kyll√§ t√§st√§"
3. **Persoonallisuus ei erotu** - Aila, Kaisa, Timo kuulostavat samalta
4. **Ei oikeaa sis√§lt√∂√§** - draft on liian tyhj√§, LLM ei keksi mit√§√§n kiinnostavaa
5. **Sekavia yhdistelmi√§** - "En sano nimi√§, mutta oon kahviolla" (???)

**Mahdolliset korjaukset:**

| Vaihtoehto | Ty√∂m√§√§r√§ | Vaikutus |
|------------|----------|----------|
| A) Rikkaammat draftit (lis√§√§ kontekstia eventist√§) | Pieni | Keskisuuri |
| B) Few-shot esimerkit per NPC-persoonallisuus | Keskisuuri | Suuri |
| C) Isompi/parempi malli (Qwen 14B, Mistral-Nemo) | Suuri | Suuri |
| D) Fine-tune nykyist√§ mallia esimerkeill√§ | Suuri | Suuri |
| E) Yksinkertaista: template-pohjaiset postaukset + satunnaisuus | Pieni | Keskisuuri |

**Suositus:** Kokeile ensin A+B (rikkaammat draftit + few-shot). Jos ei riit√§ ‚Üí mallinvaihto.

### ‚úÖ Korjattu (2025-12-16 iltap√§iv√§)

**Konsultin palautteen perusteella tehty:**

1. **Engine: Rikkaat event payloadit**
   - `PAYLOAD_OPTIONS` dict: topics, items, moods, activities per event type
   - `build_rich_payload()` generoi sis√§lt√∂√§ joka eventille
   - SMALL_TALK nyt 40% todenn√§k√∂isyydell√§ sis√§lt√§√§ target NPC:n

2. **Worker: Style-helperit**
   - `rng_for()` - deterministinen satunnaisuus event+author perusteella
   - `style_from_profile()` - muuntaa voice-dictin luonnolliseksi ohjeeksi
   - `event_facts_fi()` - poimii payloadista faktat promptiin
   - `make_draft()` - 3 variaatiota per event-tyyppi, k√§ytt√§√§ payloadin dataa

3. **Debug logging**
   - Worker logittaa author_id:t ja varoittaa mismatcheista

**Tulos:** Postaukset sis√§lt√§v√§t nyt konkreettisia yksityiskohtia:
```
ENNEN: "Kahviolla."
J√ÑLKEEN: "Riku oli kahviolla. Kes√§ on jo t√§√§ll√§."
         "T√∂iss√§ kaupassa. Sanomalehden t√§n√§√§n."
         "Asiakkaita riitti pajalla. Rauhallista t√§n√§√§n."
```

**J√§ljell√§:** LLM konkatenoi viel√§ joskus outosti - tarvitsee ehk√§ parempia few-shot esimerkkej√§ tai mallin s√§√§t√∂√§.

---

## Session Summary (2025-12-16) - LLM Gateway & Test Suite

**LLM Gateway parannukset:**
- ‚úÖ Dynaaminen JSON-schema per request (`build_json_schema()`)
- ‚úÖ Kanavakohtaiset merkkirajoitukset: FEED 280, CHAT 220, NEWS 480
- ‚úÖ `const` schemassa (mutta llama.cpp ei tue sit√§ luotettavasti)
- ‚úÖ 3-tasoinen fallback: json_schema ‚Üí json_object+schema ‚Üí json_object ‚Üí v1/completions ‚Üí /completion
- ‚úÖ JSON repair loop ep√§validille outputille (yritt√§√§ korjata LLM:ll√§)
- ‚úÖ Tiukempi system-ohje (max 2 lausetta, ei johdantoja)
- ‚úÖ `normalize_response()` pakottaa request-arvot (channel, author_id, source_event_id)

**Pytest-testipaketti:**
- ‚úÖ `tests/conftest.py` - fixtures (client, gateway_url, prompt_cases)
- ‚úÖ `tests/prompts_fi.json` - 6 suomenkielist√§ testitapausta
- ‚úÖ `tests/test_gateway_contract.py` - schema/const/pituus validaatio
- ‚úÖ `tests/test_gateway_limits.py` - soft-testit (2 lausetta, bad openers, suomi)
- ‚úÖ `scripts/smoke_gateway.py` - standalone smoke script
- ‚úÖ `requirements-dev.txt` - pytest + httpx

**Testitulokset (ennen rebuild):**
- 25 passed, 4 xpassed, 3 failed
- Failed: `test_const_locks_respected` - **gateway container ajaa vanhaa koodia!**

**üî• SEURAAVA SESSIO - aloita t√§st√§:**
```bash
# 1. Rebuild gateway container uudella koodilla
cd infra && docker-compose build llm-gateway
docker-compose up -d llm-gateway

# 2. Aja testit uudelleen
LLM_GATEWAY_URL=http://localhost:8081 pytest tests/ -v

# 3. Jos kaikki OK, merge mainiin
git checkout main && git merge feature/llm-gateway-schema-improvements
```

**Jatkoty√∂t (pending):**
- üî≤ `test_gateway_fallbacks.py` - vaatii debug-headerin `x-force-fallback`
- üî≤ `test_gateway_repair.py` - vaatii debug-headerin `x-break-json`
- üî≤ Gateway: lis√§√§ debug-headerit (vain ENV=dev)
- üî≤ Response caching (Redis)

---

## Session Summary (2025-12-14 Night) - DB Cleanup COMPLETED ‚úÖ

**Tietokannan siivous suoritettu onnistuneesti**

Alkutilanne:
- posts: ~250 rivi√§ (sis√§lsi stub-postauksia, rikkin√§isi√§ kanavia, englantia, author_id variaatioita)
- events: 2346 tapahtumaa (paljon vanhoja routine-eventtej√§)
- memories: 1020 muistoa (sidottu eventteihin)

**Suoritetut toimenpiteet:**

1. ‚úÖ **Posts-taulun siivous:**
   - Poistettu vanhat postaukset (id < 220)
   - Poistettu rikkin√§iset kanavat (NOT IN FEED/CHAT/NEWS)
   - Korjattu author_id variaatiot yhten√§isiksi (capitalize first letter):
     - `aila`, `miia`, `eero`, `osku` ‚Üí `Aila`, `Miia`, `Eero`, `Osku`
     - `NPC_Petri` ‚Üí `Petri`
     - `timo_id` ‚Üí `Timo`

2. ‚úÖ **Events-taulun siivous:**
   - Poistettu 1326 vanhaa routine-eventti√§
   - Pidetty viimeisimm√§t 1000 routine-eventti√§ + kaikki Day 1 seed eventit

3. ‚úÖ **Memories-taulun siivous:**
   - Automaattisesti siivottu CASCADE DELETE:ll√§ (579 muistoa j√§ljell√§)
   - Ei orphan-muistoja

**Lopputilanne:**
```
Table          | Count | Size    | Status
---------------|-------|---------|--------
posts          | 55    | 160 kB  | ‚úÖ Clean, Finnish, valid channels
events         | 1020  | 776 kB  | ‚úÖ Recent events + Day 1 seeds
memories       | 579   | 272 kB  | ‚úÖ Auto-cleaned via CASCADE
relationships  | 14    | 64 kB   | ‚úÖ OK
goals          | 18    | 48 kB   | ‚úÖ OK
---------------|-------|---------|--------
TOTAL          |       | ~1.3 MB | ‚úÖ Optimized
```

**Tulokset:**
- ‚úÖ Kaikki postaukset laadukasta suomea (Qwen2.5-generoidut)
- ‚úÖ Author_id:t yhten√§isi√§ (12 uniikkia NPC:t√§)
- ‚úÖ Channels validit (FEED, CHAT)
- ‚úÖ Tietokanta optimoitu (~56% pienempi)
- ‚úÖ Ei dataintegriteetti-ongelmia

---

## Session Summary (2025-12-14 Evening)

**Major Finnish Language Quality Upgrade - Qwen2.5 + Catalog Prompts**

Problem identified:
- Mistral 7B produced poor Finnish quality (grammar errors, English leakage)
- Hardcoded prompts lacked channel-specific guidance
- No NPC personality integration in prompts
- JSON output unreliable without schema constraints

Solutions implemented:
1. **Upgraded to Qwen2.5 7B Instruct Q4_K_M** (4.4GB, excellent multilingual)
2. **JSON schema constraint** in LLM gateway - forces valid structure, prevents essays
3. **Wired catalog prompt templates** from `event_types.json` to workers
4. **NPC profile integration** - personality, voice, name used in prompts
5. **Enhanced Finnish instructions** - channel-specific, proper length limits
6. Lowered temperature 0.7 ‚Üí 0.3 for stability

Results (MASSIVE improvement):
- ‚úÖ **Natural colloquial Finnish** - "Saunaan meni. Uusi alku. M√§ en oo t√§√§ll√§ draaman takia."
- ‚úÖ **No English leakage** - consistent Finnish throughout
- ‚úÖ **NPC personalities show** - Aila dramatic, others varied styles
- ‚úÖ **Valid JSON always** - schema constraint works perfectly
- ‚úÖ **Channel-specific tone** - FEED vs CHAT clearly different
- ‚úÖ **Contextual tags** - relevant to content
- ‚úÖ **Punchy social media style** - no long essays

Example posts generated:
```
Miia (CHAT): "No joo siis‚Ä¶ Aika villi√§. Ei oo ok. Miten sinulla menee?"
Jari (FEED): "Kaupassa j√§lleen. S√§√§nn√∂t on syyst√§. Katsotaan nyt."
Aila (FEED): "En sano nimi√§, mutta h√§nen ostoksensa olivat jopa hienompia kuin h√§nen lausuntojensa."
```

Files changed:
- `infra/.env` - Qwen2.5 7B model, temperature 0.3
- `services/workers/app/worker.py` - catalog prompt loading, NPC profile integration
- `services/llm_gateway/app/main.py` - JSON schema constraint, enhanced system message
- Downloaded: `models/qwen2.5-7b-instruct-q4_k_m.gguf` (4.4GB)

**System now demo-ready with high-quality Finnish content generation!**

---

## Session Summary (2025-12-14 Morning)

**Bugfix: Engine restart event generation**

Problem discovered:
- Simulation had stopped generating events ~2 days ago
- Engine was running but no new events in database
- Root cause: DNS failure crashed engine, on restart `tick_index` started from 0
- Event IDs like `evt_routine_{tick}_{npc}` already existed in DB
- `ON CONFLICT DO NOTHING` silently rejected all new events

Fix applied (`runner.py`):
- Added `fetch_latest_tick_index()` to query max tick from existing events
- Engine now resumes from `last_tick + 1` instead of 0
- RNG state advanced to match resumed position for determinism
- Log now shows `resume_tick=N` on startup

**GPU LLM Server activation**

- Switched from CPU to GPU llama.cpp server
- Updated `.env`: `LLM_SERVER_URL=http://llm-server-gpu:8080`
- Flash Attention enabled, 4 parallel slots

**Missing event types added**

- Added `LOCATION_VISIT` and `CUSTOMER_INTERACTION` to `event_types.json`
- These routine events now have render channels (FEED) configured
- Lowered impact thresholds for more realistic posting behavior:
  - FEED: 0.6 ‚Üí 0.15
  - CHAT: 0.4 ‚Üí 0.10
  - NEWS: 0.8 ‚Üí 0.5

**Full pipeline verified working**

- Engine ‚Üí Redis queue ‚Üí Workers ‚Üí LLM Gateway ‚Üí GPU ‚Üí Posts in DB
- 40+ posts generated during testing
- Pipeline processes ~1 event/second with GPU acceleration

**Village monitor tool added**

- `tools/village_monitor.py` - CLI for real-time activity feed
- Shows events and posts side-by-side with colors
- Supports `--live` mode, filtering by `--npc`, `--type`, `--channel`

**Next session priorities:**
1. üî• Fix prompt templates for proper Finnish content
2. üî• Fix channel parsing (posts showing wrong channel names)
3. Consider: Add more dramatic event types for variety

**Known issues:**
- Some posts have malformed channel names (prompt parsing issue)
- LLM sometimes outputs English or raw event data instead of Finnish posts
- Prompt templates need refinement for better content quality

---

## Session Summary (2025-12-12)

**Major accomplishments:**
- ‚úÖ Implemented post-Day1 continuous simulation with routine event injector
- ‚úÖ Fixed CORS issues in API and gateway
- ‚úÖ Configured llama.cpp with CPU/GPU profiles
- ‚úÖ Integrated real LLM adapter (no longer stub!)
- ‚úÖ All smoke tests passing
- ‚úÖ Comprehensive documentation with Mermaid diagrams
- ‚úÖ README with quick start guide

**Technical details:**
- Routine injector generates events every 10 ticks (configurable)
- Deterministic NPC round-robin + seeded RNG for variety
- Impact scoring working (0.23-0.51 range observed)
- Events ‚Üí memories ‚Üí relationships pipeline functional
- 100+ routine events generated in test run

**Ready for next session:**
- System is demo-ready for "Day 1 ‚Üí continuous sim" showcase
- Next: Wire catalog prompts for better content quality
- Consider: Daily NEWS digest for narrative structure
