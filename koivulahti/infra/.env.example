ENV=dev
POSTGRES_USER=koivulahti
POSTGRES_PASSWORD=koivulahti
POSTGRES_DB=koivulahti
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
REDIS_URL=redis://redis:6379/0
RENDER_QUEUE=render_jobs
SIM_SEED=1234
SIM_TICK_MS=1000
IMPACT_THRESHOLD_FEED=0.6
IMPACT_THRESHOLD_CHAT=0.4
IMPACT_THRESHOLD_NEWS=0.8

# LLM server selection
# Set to the active server depending on profile:
# - CPU run: LLM_SERVER_URL=http://llm-server-cpu:8080
# - GPU run: LLM_SERVER_URL=http://llm-server-gpu:8080
LLM_SERVER_URL=http://llm-server:8080

# Stable defaults (official ggml-org images)
LLM_SERVER_IMAGE_CPU=ghcr.io/ggml-org/llama.cpp:server
LLM_SERVER_IMAGE_GPU=ghcr.io/ggml-org/llama.cpp:server-cuda

# Model and generation settings
LLM_MODEL_PATH=/models/your-7b-instruct.Q4_K_M.gguf
LLM_CONTEXT=4096
LLM_TEMPERATURE=0.7
LLM_PROVIDER=llama_cpp
LLM_GATEWAY_URL=http://llm-gateway:8081
